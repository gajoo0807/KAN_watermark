{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iPv5Nnr8iGf"
      },
      "source": [
        "# Implementation of a KAN for regression\n",
        "In this notebook I implement a Kolmogorov-Arnold Network (KAN) for the use of regression and compare it against a neural network of a similar architecture."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRMpDTp_cVt5"
      },
      "source": [
        "## Initialisations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrVEGBzEcUQc",
        "outputId": "0ffd8432-65a5-4d4f-9c76-5e682ff9a386"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from kan import *\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RE1svm9cXkX"
      },
      "source": [
        "## Loading the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMwDaT0icUJD",
        "outputId": "313d1117-4c58-4ecf-a68b-bf1116a80d34"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16512/16512 [00:01<00:00, 12605.20it/s]\n",
            "100%|██████████| 4128/4128 [00:00<00:00, 12544.64it/s]\n"
          ]
        }
      ],
      "source": [
        "def load_calhous_dataset():\n",
        "    # Load California housing dataset\n",
        "    calhous = fetch_california_housing()\n",
        "    data = calhous.data\n",
        "    target = calhous.target\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    data = scaler.fit_transform(data)\n",
        "\n",
        "    # Convert to PyTorch tensors\n",
        "    data_tensor = torch.tensor(data, dtype=torch.float32)\n",
        "    target_tensor = torch.tensor(target, dtype=torch.float32)\n",
        "\n",
        "    # Split dataset into train and test sets\n",
        "    train_data, test_data, train_target, test_target = train_test_split(data_tensor, target_tensor, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Create data loaders (optional, if you want to batch and shuffle the data)\n",
        "    train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(train_data, train_target), batch_size=1, shuffle=True)\n",
        "    test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(test_data, test_target), batch_size=1, shuffle=False)\n",
        "\n",
        "    train_inputs = torch.empty(0, 8, device=device)\n",
        "    train_labels = torch.empty(0, dtype=torch.long, device=device)\n",
        "    test_inputs = torch.empty(0, 8, device=device)\n",
        "    test_labels = torch.empty(0, dtype=torch.long, device=device)\n",
        "\n",
        "    # Concatenate all data into a single tensor on the specified device\n",
        "    for data, labels in tqdm(train_loader):\n",
        "        train_inputs = torch.cat((train_inputs, data.to(device)), dim=0)\n",
        "        train_labels = torch.cat((train_labels, labels.to(device)), dim=0)\n",
        "\n",
        "    for data, labels in tqdm(test_loader):\n",
        "        test_inputs = torch.cat((test_inputs, data.to(device)), dim=0)\n",
        "        test_labels = torch.cat((test_labels, labels.to(device)), dim=0)\n",
        "\n",
        "    dataset = {}\n",
        "    dataset['train_input'] = train_inputs\n",
        "    dataset['test_input'] = test_inputs\n",
        "    dataset['train_label'] = train_labels.reshape(-1, 1)\n",
        "    dataset['test_label'] = test_labels.reshape(-1, 1)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "calhous_dataset = load_calhous_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDBtdgGocUHM",
        "outputId": "c5c54a1a-0367-4d0b-988f-d8040ed25a1b"
      },
      "outputs": [],
      "source": [
        "print(\"Train data shape: {}\".format(calhous_dataset['train_input'].shape))\n",
        "print(\"Train target shape: {}\".format(calhous_dataset['train_label'].shape))\n",
        "print(\"Test data shape: {}\".format(calhous_dataset['test_input'].shape))\n",
        "print(\"Test target shape: {}\".format(calhous_dataset['test_label'].shape))\n",
        "print(\"====================================\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7ERosp1iM17"
      },
      "source": [
        "## Creating and Training the KAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xkjQDBTnNFHw"
      },
      "outputs": [],
      "source": [
        "image_folder = 'video_img'\n",
        "\n",
        "model = KAN(width=[8, 3, 1], grid=3, k=3, seed=5, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = torch.normal(0,1,size=(100,8)).to(device)\n",
        "model(x) # do a forward pass to obtain model.acts\n",
        "# model.get_range(0,0,0)\n",
        "print(f\"{model.act_fun[0].grid[0].data=}\") # Check the initial grid, size = grid + 1\n",
        "print(f\"{model.act_fun[0].coef[0].data=}\")  # Check the initial coef, size = grid + k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhNKU6T1iLWe",
        "outputId": "c1050905-cf4e-428f-ff3f-80d82944b34d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "train loss: 6.07e-01 | test loss: 1.04e+00 | reg: 4.91e+00 : 100%|█| 100/100 [07:25<00:00,  4.46s/it\n"
          ]
        }
      ],
      "source": [
        "def train_mse():\n",
        "    with torch.no_grad():\n",
        "        predictions = model(calhous_dataset['train_input'])\n",
        "        mse = torch.nn.functional.mse_loss(predictions, calhous_dataset['train_label'])\n",
        "    return mse\n",
        "\n",
        "def test_mse():\n",
        "    with torch.no_grad():\n",
        "        predictions = model(calhous_dataset['test_input'])\n",
        "        mse = torch.nn.functional.mse_loss(predictions, calhous_dataset['test_label'])\n",
        "    return mse\n",
        "\n",
        "# results = model.train(calhous_dataset, opt=\"LBFGS\", device=device, metrics=(train_mse, test_mse),\n",
        "#                       loss_fn=torch.nn.MSELoss(), steps=50, lamb=0.01, lamb_entropy=2., save_fig=True, img_folder=image_folder)\n",
        "\n",
        "results = model.train(calhous_dataset, opt=\"LBFGS\", device=device, metrics=(train_mse, test_mse),\n",
        "                      loss_fn=torch.nn.MSELoss(), steps=100, lamb=0.01, lamb_entropy=2., save_fig=True, img_folder=image_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8hG6q3zujPG",
        "outputId": "2a99f4b0-896f-47b2-a980-cdfb6a314f11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train MSE: 0.3680436611175537, Test MSE: 1.0905240774154663\n"
          ]
        }
      ],
      "source": [
        "print(f\"Train MSE: {results['train_mse'][-1]:.5f}, Test MSE: {results['test_mse'][-1]:.5f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def detect_inference_time():\n",
        "    import random\n",
        "    import time\n",
        "\n",
        "    # 从测试集中随机选择一个样本\n",
        "    index = random.randint(0, len(calhous_dataset['test_input']) - 1)\n",
        "    input_data = calhous_dataset['test_input'][index].unsqueeze(0)\n",
        "    label = calhous_dataset['test_label'][index]\n",
        "\n",
        "    # 将输入数据传入模型进行预测\n",
        "    start = time.time()\n",
        "    with torch.no_grad():\n",
        "        output = model(input_data)\n",
        "    end = time.time()\n",
        "    # print(f\"Inference time: {end - start} seconds\")\n",
        "    return end - start\n",
        "\n",
        "def print_act():\n",
        "    for i in model.acts_scale:\n",
        "        print(i)\n",
        "        print('\\n\\n')\n",
        "\n",
        "time = []\n",
        "for i in range(11):\n",
        "    time.append(detect_inference_time())\n",
        "print(time)\n",
        "print(sum(time[1:]) / (len(time)-1))\n",
        "# print_act()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mode = \"auto\" # \"manual\"\n",
        "\n",
        "if mode == \"manual\":\n",
        "    # manual mode\n",
        "    model.fix_symbolic(0,0,0,'sin');\n",
        "    model.fix_symbolic(0,1,0,'x^2');\n",
        "    model.fix_symbolic(1,0,0,'exp');\n",
        "elif mode == \"auto\":\n",
        "    # automatic mode\n",
        "    lib = ['x','x^2','x^3','x^4','exp','log','sqrt','tanh','sin','abs']\n",
        "    model.auto_symbolic(lib=lib)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 721
        },
        "id": "ll0aE1WW9FEK",
        "outputId": "ad5f27d7-a28b-4dde-9feb-e7ad93a1510b"
      },
      "outputs": [],
      "source": [
        "model.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPbmkBTBNSDe",
        "outputId": "dc4c7c69-c45a-4b56-d086-59b0a2f102f9"
      },
      "outputs": [],
      "source": [
        "import moviepy.video.io.ImageSequenceClip\n",
        "\n",
        "video_name='video'\n",
        "fps=10\n",
        "\n",
        "fps = fps\n",
        "files = os.listdir(image_folder)\n",
        "train_index = []\n",
        "for file in files:\n",
        "    if file[0].isdigit() and file.endswith('.jpg'):\n",
        "        train_index.append(int(file[:-4]))\n",
        "\n",
        "train_index = np.sort(train_index)\n",
        "\n",
        "image_files = [image_folder+'/'+str(train_index[index])+'.jpg' for index in train_index]\n",
        "\n",
        "clip = moviepy.video.io.ImageSequenceClip.ImageSequenceClip(image_files, fps=fps)\n",
        "clip.write_videofile(video_name+'.mp4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_2757701/1417181042.py:13: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  images.append(imageio.imread(img_path))\n"
          ]
        }
      ],
      "source": [
        "import imageio\n",
        "def generate_train_gif(l, i, j, step, model_index=0):\n",
        "    # 设置图片所在的文件夹和输出的 GIF 文件名\n",
        "    folder = f'train_process/neuron_{l}_{i}_{j}'\n",
        "    output_gif = f'neuron_{l}_{i}_{j}.gif'\n",
        "    save_folder = f'fingerprint/model_{model_index}'\n",
        "\n",
        "    # 收集文件夹中所有的 PNG 文件名\n",
        "    images = []\n",
        "    for i in range(step):  # 假设有 50 张图片，编号从 0 到 49\n",
        "        img_path = os.path.join(folder, f'step_{i}.png')\n",
        "        if os.path.exists(img_path):  # 确认图片存在\n",
        "            images.append(imageio.imread(img_path))\n",
        "\n",
        "    # 将收集到的图片列表制作成 GIF\n",
        "    imageio.mimsave(os.path.join(save_folder, output_gif), images, fps=10)  # fps 是每秒帧数\n",
        "index = 1\n",
        "for i in range(8):\n",
        "    for j in range(3):\n",
        "        generate_train_gif(0,i,j,100, index)\n",
        "for i in range(3):\n",
        "    generate_train_gif(1, i, 0, 100, index)\n",
        "# generate_train_gif(0,0,0,100, index)\n",
        "# generate_train_gif(0,1,1,100, index)\n",
        "# generate_train_gif(0,6,2,100, index)\n",
        "# generate_train_gif(1,0,0,100, index)\n",
        "# generate_train_gif(1,1,0,100, index)\n",
        "# generate_train_gif(1,2,0,100, index)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save_ckpt('test.pth') # Save model to ./model_ckpt/test.pth\n",
        "model.load_ckpt('test.pth') # Load model from ./model_ckpt/test.pth\n",
        "\n",
        "# 可用作finetune attack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def prune_neuron():\n",
        "    # print(model.acts_scale)\n",
        "    # for i in model.acts_scale:\n",
        "    #     print(torch.mean(i))\n",
        "    #     print(i.type())\n",
        "    model.prune(threshold=1e-4)\n",
        "    model.plot()\n",
        "\n",
        "    \n",
        "\n",
        "    # acts_scale_mean = torch.mean(model.acts_scale)\n",
        "    # print(acts_scale_mean)\n",
        "\n",
        "prune_neuron()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.prune()\n",
        "model.plot(mask=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBD58aME1Rvd"
      },
      "source": [
        "# Implementation of a Neural Network for comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeOsPZiB9MSS"
      },
      "source": [
        "## Misc Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WxOUQTTiuAja"
      },
      "outputs": [],
      "source": [
        "class CalHousNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CalHousNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(8, 3)  # 8 inputs to 5 hidden nodes\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(3, 1)  # 5 hidden nodes to 3 outputs\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "def train_model(model, train_loader, criterion, optimizer, num_epochs=25):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)  # Move data to the specified device\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
        "\n",
        "def test_model(model, test_loader):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    total_count = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)  # Move data to the specified device\n",
        "            outputs = model(inputs)\n",
        "            loss = torch.nn.functional.mse_loss(outputs, labels, reduction='sum')\n",
        "            total_loss += loss.item()\n",
        "            total_count += labels.size(0)\n",
        "\n",
        "    # Calculate the average MSE over all batches\n",
        "    average_mse = total_loss / total_count\n",
        "    print(f'Mean Squared Error: {average_mse}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-99o3TR1uN1"
      },
      "outputs": [],
      "source": [
        "def load_calhous_dataset():\n",
        "    # Load California housing dataset\n",
        "    calhous = fetch_california_housing()\n",
        "    data = calhous.data\n",
        "    target = calhous.target\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    data = scaler.fit_transform(data)\n",
        "\n",
        "    # Convert to PyTorch tensors\n",
        "    data_tensor = torch.tensor(data, dtype=torch.float32)\n",
        "    target_tensor = torch.tensor(target, dtype=torch.float32).reshape(-1, 1)\n",
        "\n",
        "    # Split dataset into train and test sets\n",
        "    train_data, test_data, train_target, test_target = train_test_split(data_tensor, target_tensor, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Create data loaders (optional, if you want to batch and shuffle the data)\n",
        "    train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(train_data, train_target), batch_size=256, shuffle=True)\n",
        "    test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(test_data, test_target), batch_size=256, shuffle=False)\n",
        "\n",
        "    return train_loader, test_loader\n",
        "\n",
        "train_loader, test_loader = load_calhous_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJYeBGm9vj28",
        "outputId": "1b10911b-f937-4f21-8cc7-586b74cac384"
      },
      "outputs": [],
      "source": [
        "dataiter = iter(train_loader)\n",
        "data, labels = next(dataiter)\n",
        "print(\"Train data shape: {}\".format(data.shape))\n",
        "print(\"Train target shape: {}\".format(labels.shape))\n",
        "dataiter = iter(test_loader)\n",
        "data, labels = next(dataiter)\n",
        "print(\"Test data shape: {}\".format(data.shape))\n",
        "print(\"Test target shape: {}\".format(labels.shape))\n",
        "print(\"====================================\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hg219SyH9NrO"
      },
      "source": [
        "## Train and Evaluate the NN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbsyfVGd1cX1",
        "outputId": "e5b8d8b7-abda-4f53-fa54-f38c83f3b561"
      },
      "outputs": [],
      "source": [
        "model = CalHousNet().to(device)\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.05)\n",
        "\n",
        "train_model(model, train_loader, criterion, optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zw5MP7SSwmOq",
        "outputId": "89d40fbe-1dcb-486b-8ac7-df08c4cc5f05"
      },
      "outputs": [],
      "source": [
        "test_model(model, test_loader)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "LRMpDTp_cVt5",
        "7RE1svm9cXkX"
      ],
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
